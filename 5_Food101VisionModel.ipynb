{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34cbecd4-46f8-443d-b900-ef55bff09351",
   "metadata": {},
   "source": [
    "# Train model\n",
    "* get a pretrained EfficientNetB2 model\n",
    "* Do training on Food101 dataset\n",
    "  * First try 20% data\n",
    "  * Then try full dataset\n",
    "* Save model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f94d01-283f-4011-a4b6-8053e7320ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 2.0.1+cu118 | torchvision 0.15.2+cu118\n"
     ]
    }
   ],
   "source": [
    "# import torch, torchvision modules\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "print(f\"torch {torch.__version__} | torchvision {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e4c9ed-349b-4f83-820a-a6edbec482b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchinfo for model summary\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    !pip install torchinfo\n",
    "    from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c93ea16-cc9c-4093-950c-6648d7d9821e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 18:04:43.780636: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-21 18:04:44.097440: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-21 18:04:45.011177: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import modules from sources\n",
    "from sources import utils, datasetup, engine, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b355f-e6b2-4fa3-bae0-e8e00dbc3779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device agnostic. For training, we can use cpu or gpu depend on available hardware\n",
    "# when deploying on gradio, we only have free cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a80c15-5c23-4b3d-a44c-958f88698fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup pretrained EfficientNet2 for 101 food classes\n",
    "model, model_transforms = models.create_effnet(\n",
    "    effnet_version=2,\n",
    "    num_class_names=101\n",
    ")\n",
    "model_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b73183-4e63-4586-851f-d51c1ac153e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check summary of the model\n",
    "summary(\n",
    "    model=model,\n",
    "    input_size=[32, 3, 224, 224],\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef11c1d-6884-41fc-826b-36d6895a616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose additional transformation for train dataset\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.TrivialAugmentWide(),\n",
    "    model_transforms\n",
    "])\n",
    "train_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad829c9-3793-4bbf-a50d-c9520c835d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup dataloaders\n",
    "from pathlib import Path\n",
    "from torchvision import datasets\n",
    "\n",
    "data_dir = Path(\"/gpfs/alpine/chm135/proj-shared/buu/tmp\")\n",
    "\n",
    "train_data = datasets.Food101(\n",
    "    root=data_dir,\n",
    "    split=\"train\",\n",
    "    transform=train_transforms,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.Food101(\n",
    "    root=data_dir,\n",
    "    split=\"test\",\n",
    "    transform=model_transforms,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b01235-314c-4a2b-bf90-83c9bcc5ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train class names\n",
    "class_names = train_data.classes\n",
    "class_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c66b4e-b6f0-48f3-a9fe-69c823b958d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup function to get 20% of training data\n",
    "def split_dataset(dataset: torchvision.datasets,\n",
    "                 split_size: float=0.2):\n",
    "\n",
    "    length_1 = int(len(dataset) * split_size)\n",
    "    length_2 = len(dataset) - length_1\n",
    "    \n",
    "    random_split_1, random_split_2 = torch.utils.data.random_split(\n",
    "        dataset=dataset,\n",
    "        lengths=[length_1, length_2]\n",
    "    )\n",
    "\n",
    "    return random_split_1, random_split_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe7338-88da-401e-80e6-e34b6f928a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 20% of dataset for train and test set\n",
    "train_data_20, _ = split_dataset(\n",
    "    dataset=train_data,\n",
    "    split_size=0.2\n",
    ")\n",
    "\n",
    "test_data_20, _ = split_dataset(\n",
    "    dataset=test_data,\n",
    "    split_size=0.2\n",
    ")\n",
    "\n",
    "print(f\"train length: {len(train_data_20)} | test length: {len(test_data_20)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7f631-19e2-41e9-a863-1d231612f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup train and test dataloaders\n",
    "import os\n",
    "import torch\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_data_20,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test_data_20,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "print(f\"{train_dataloader} | {test_dataloader}\")\n",
    "print(f\"train and test length: {len(train_dataloader)} | {len(test_dataloader)}\")\n",
    "\n",
    "train_dataloader, test_dataloader, len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f96bf7-bad2-4049-9b40-4c8536a20741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca46ac4a-f09b-4f4a-9078-c6dcf886548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using train function from engine module\n",
    "results = engine.train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    epochs=1,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc8eb26-dcad-4bbb-9744-86b78adc3926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,4))\n",
    "ax[0].plot(results[\"train_loss\"], label=\"train_loss\")\n",
    "ax[0].plot(results[\"test_loss\"], label=\"test_loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(results[\"train_acc\"], label=\"train_acc\")\n",
    "ax[1].plot(results[\"test_acc\"], label=\"test_acc\")\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c34b967-6432-471a-8c0b-17fdf369bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train model to `saved_models`\n",
    "saved_model_path = utils.save_model(\n",
    "    model=model,\n",
    "    model_dir=\"saved_models\",\n",
    "    model_name_grid=[model.name]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813dbad7-44a9-4b0c-b681-9f2e9869128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the size of trained model\n",
    "saved_model_path = Path(\"saved_models/EfficientNet_B2.pth\")\n",
    "model_size = Path(saved_model_path).stat().st_size // (1024*1024)\n",
    "model_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420c77c9-9430-41bd-8400-5cf365f1e384",
   "metadata": {},
   "source": [
    "# Read model from source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e72524-eaa3-4817-a740-c0c79534615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pretrained model\n",
    "model, model_transforms = models.create_effnet(\n",
    "    effnet_version=2,\n",
    "    num_class_names=101,\n",
    "    device=torch.device(\"cpu\")\n",
    ")\n",
    "\n",
    "next(iter(model.parameters())).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b46f99-97ad-45e3-8a81-abaf8b6d88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check summary\n",
    "summary(\n",
    "    model=model,\n",
    "    input_size=[32, 3, 224, 224],\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c56f55-a48b-4a84-96f0-08f87317a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from file\n",
    "model.load_state_dict(torch.load(\n",
    "    f=saved_model_path,\n",
    "    map_location=torch.device(\"cpu\")\n",
    "))\n",
    "\n",
    "next(iter(model.parameters())).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b965b4-6176-4534-816b-bb7cf57d420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict function\n",
    "import random\n",
    "from typing import Tuple, Dict, List\n",
    "from timeit import default_timer as timer\n",
    "import PIL\n",
    "\n",
    "def predict(img: PIL.Image) -> Tuple[Dict, float]:\n",
    "\n",
    "    # start timer\n",
    "    start_time = timer()\n",
    "    \n",
    "    # convert image to torch.tensor\n",
    "    img_transformed = model_transforms(img).unsqueeze(dim=0)\n",
    "\n",
    "    # predict food label probability\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        pred_prob = torch.softmax(model(img_transformed), dim=1)\n",
    "\n",
    "    pred_prob_dict = {\n",
    "        class_names[i]: float(pred_prob[0][i]) for i in range(len(class_names))\n",
    "    }\n",
    "\n",
    "    # wall time for prediction\n",
    "    pred_time = timer() - start_time\n",
    "\n",
    "    return pred_prob_dict, pred_time\n",
    "\n",
    "random_path = random.choice(list(data_dir.glob(\"*/*/*/*\")))\n",
    "img = PIL.Image.open(random_path)\n",
    "predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab4481-4a52-42b5-853c-c5b02d5a394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write class names to file\n",
    "with open(\"class_names.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795d8e6-1602-4449-b11a-7560233e4cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read class name file to list\n",
    "with open(\"class_names.txt\", \"r\") as f:\n",
    "    read_class_name = [cls.strip() for cls in f.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f181a-9897-4b39-b27e-e4a23406bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dir = Path(\"examples\")\n",
    "example_dir.mkdir(parents=True, exist_ok=True)\n",
    "random_paths = random.sample(list(data_dir.glob(\"*/*/*/*\")), k=3)\n",
    "\n",
    "# copy three example to example directory\n",
    "import shutil\n",
    "for rp in random_paths:\n",
    "    shutil.copy2(dst=example_dir, src=rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29033e58-1ede-42cb-85f3-3e59bf256cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af0ea3e-563c-451c-913d-7a2ec6795bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d610e56-bb46-4142-98c2-f1a554e5068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import gradio as gr\n",
    "except:\n",
    "    !pip install typing-extensions --upgrade\n",
    "    !pip install -q gradio\n",
    "    import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18c58a-e359-47cf-87b9-e7fed2509093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sources import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff61160c-c801-4895-b267-86b0f861d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create demo directory\n",
    "Path(\"demo\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06841c23-39c0-475b-9a80-1fe8d2daa0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile demo/app.py\n",
    "\n",
    "from typing import Tuple, Dict\n",
    "import os\n",
    "import gradio as gr\n",
    "import PIL\n",
    "# get pretrained model\n",
    "model, model_transforms = models.create_effnet(\n",
    "    effnet_version=2,\n",
    "    num_class_names=101,\n",
    "    device=torch.device(\"cpu\")\n",
    ")\n",
    "\n",
    "# load model from file\n",
    "model.load_state_dict(torch.load(\n",
    "    f=\"saved_models/EfficientNet_B2.pth\",\n",
    "    map_location=torch.device(\"cpu\")\n",
    "))\n",
    "\n",
    "# read class names from file\n",
    "with open(\"class_names.txt\", \"r\") as f:\n",
    "    class_names = [cls.strip() for cls in f.readlines()]\n",
    "\n",
    "def predict(img: PIL.Image) -> Tuple[Dict, float]:\n",
    "\n",
    "    # start timer\n",
    "    start_time = timer()\n",
    "    \n",
    "    # convert image to torch.tensor\n",
    "    img_transformed = model_transforms(img).unsqueeze(dim=0)\n",
    "\n",
    "    # predict food label probability\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        pred_prob = torch.softmax(model(img_transformed), dim=1)\n",
    "\n",
    "    pred_prob_dict = {\n",
    "        class_names[i]: pred_prob[0][i] for i in range(len(class_names))\n",
    "    }\n",
    "\n",
    "    # wall time for prediction\n",
    "    pred_time = timer() - start_time\n",
    "\n",
    "    return pred_prob_dict, pred_time\n",
    "\n",
    "\n",
    "# create gradio app\n",
    "example_list = [[\"examples/\" + example] for example in os.listdir(\"examples\")]\n",
    "\n",
    "# Create Gradio interface \n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=[\n",
    "        gr.Label(num_top_classes=5, label=\"Predictions\"),\n",
    "        gr.Number(label=\"Prediction time (s)\"),\n",
    "    ],\n",
    "    examples=example_list,\n",
    "    title=\"big food vision model\",\n",
    "    description=\"101 food classes\",\n",
    "    article=\"\",\n",
    ")\n",
    "\n",
    "# Launch the app!\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cfeb3e-7aad-4b1b-9933-af1a62398c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924f6ba-20ec-4a90-aaf6-2f777976ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e72c69-2b92-45d1-b795-8a54893a8e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359cf78a-f4f8-4aa6-99f1-a1a6e3a48162",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile demo/requirements.txt\n",
    "torch==2.0.1\n",
    "torchvision==0.15.2\n",
    "gradio==4.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09822d17-6504-4900-beaf-5dec5245286e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OLCF-CUDA11 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
