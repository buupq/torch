{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/eEUov8+SE6lE+9iurdK9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buupq/torch/blob/main/tinyVGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create sources directory\n",
        "from pathlib import Path\n",
        "\n",
        "sources = Path(\"sources\")\n",
        "sources.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "KjDCwypdGSXK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKfZWtzNjFPo",
        "outputId": "fb75a1e2-cb9d-49d6-c02c-105f8a8ad2f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sources/utils.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile sources/utils.py\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "\n",
        "def list_file_tree(\n",
        "    targ_dir=\".\",\n",
        "    print_all_files=False,\n",
        "    num_file_cap=2,\n",
        "    print_dir_only=True):\n",
        "\n",
        "    \"\"\"list directories and files of a target directory\n",
        "    Args:\n",
        "        targ_dir: target directory\n",
        "        print_all_files: print all available directory and files in targ_dir\n",
        "        print_dir_only: print directory tree only\n",
        "        num_file_cap: maximum number of files listed\n",
        "    Examples:\n",
        "        list_file_tree(targ_dir=\".\", print_dir_only=True)\n",
        "        would return only list of directory\n",
        "    \"\"\"\n",
        "    if not Path(targ_dir).is_dir():\n",
        "        return f\"{targ_dir}: does not exist!\"\n",
        "\n",
        "    for root, dirs, files in list(os.walk(targ_dir)):\n",
        "        # print directories\n",
        "        level = root.replace(str(targ_dir), \"\").count(os.sep)\n",
        "        indent = \" \" * 3 * level\n",
        "        print(f\"{indent} {bcolors.OKBLUE} {root} {bcolors.ENDC}\")\n",
        "\n",
        "        if not print_dir_only:\n",
        "        # print files in directory\n",
        "            subindent = \" \" * 3 * (level + 1)\n",
        "            num_files = 0\n",
        "            if print_all_files:\n",
        "                num_file_cap = len(files)\n",
        "            for file in files:\n",
        "                if num_files < num_file_cap:\n",
        "                    print(f\"{subindent} {bcolors.OKGREEN} {file} {bcolors.ENDC}\")\n",
        "                    num_files += 1\n",
        "                    if num_files == num_file_cap:\n",
        "                        print(f\"{subindent} and {len(files)} other files...\")\n",
        "\n",
        "\n",
        "# download data\n",
        "from pathlib import Path\n",
        "from zipfile import ZipFile\n",
        "import requests\n",
        "\n",
        "def download_data(url):\n",
        "    \"\"\"Download file from an url to data, extract files to images folder\n",
        "    Args:\n",
        "        url: url to the data source\n",
        "    Returns:\n",
        "        image_path, train_path, test_path = download_data(url=url)\n",
        "            image_path: folder to store train and test images\n",
        "            train_path: folder to store train data\n",
        "            test_path: folder to store test data\n",
        "    \"\"\"\n",
        "\n",
        "    # create data directory\n",
        "    data_path = Path(\"data\")\n",
        "    image_path = data_path / \"images\"\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # download zip file to data/\n",
        "    request = requests.get(url)\n",
        "    with open(data_path / \"images.zip\", \"wb\") as f:\n",
        "        f.write(request.content)\n",
        "\n",
        "    # extract images to data/images\n",
        "    with ZipFile(data_path / \"images.zip\") as zip_ref:\n",
        "        zip_ref.extractall(image_path)\n",
        "\n",
        "    # train and test directories\n",
        "    train_dir = image_path / \"train\"\n",
        "    test_dir = image_path / \"test\"\n",
        "\n",
        "\n",
        "    return image_path, train_dir, test_dir\n",
        "\n",
        "\n",
        "def save_model(model:torch.nn.Module,\n",
        "               model_dir: str):\n",
        "\n",
        "    model_save_path = Path(model_dir) / (model.name + \".pth\")\n",
        "\n",
        "    torch.save(\n",
        "        obj = model.state_dict(),\n",
        "        f = model_save_path\n",
        "    )\n",
        "\n",
        "    return model_save_path\n",
        "\n",
        "def load_saved_model(loaded_model: torch.nn.Module,\n",
        "                     model_saved_path: str):\n",
        "\n",
        "    loaded_model.load_state_dict(torch.load(model_saved_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JxzxLHYcjTB5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sources/datasetup.py\n",
        "# create train and test dataloader\n",
        "#     using ImageFolder\n",
        "#     using DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "def create_compose_transforms():\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize(size = (64, 64)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.RandomHorizontalFlip(p=0.5)\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize(size=(64,64)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    return train_transform, test_transform\n",
        "\n",
        "\n",
        "def create_dataloaders(train_dir: str,\n",
        "                    test_dir: str,\n",
        "                    train_transform: torchvision.transforms.Compose,\n",
        "                    test_transform: torchvision.transforms.Compose,\n",
        "                    batch_size: int,\n",
        "                    num_workers: int):\n",
        "\n",
        "    # create train data from image folder\n",
        "    train_data = ImageFolder(\n",
        "        root = train_dir,\n",
        "        transform=train_transform,\n",
        "        target_transform=None\n",
        "    )\n",
        "\n",
        "    # create test data from image folder\n",
        "    test_data = ImageFolder(\n",
        "        root = test_dir,\n",
        "        transform = test_transform,\n",
        "        target_transform = None\n",
        "    )\n",
        "\n",
        "    # get train data class names\n",
        "    class_names = train_data.classes\n",
        "\n",
        "    # create train dataloader\n",
        "    train_dataloader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size = batch_size,\n",
        "        num_workers = num_workers,\n",
        "        shuffle = True\n",
        "    )\n",
        "\n",
        "    # create test dataloader\n",
        "    test_dataloader = DataLoader(\n",
        "        test_data,\n",
        "        batch_size = batch_size,\n",
        "        num_workers = num_workers\n",
        "    )\n",
        "\n",
        "    return train_dataloader, test_dataloader, class_names\n"
      ],
      "metadata": {
        "id": "s2rj2L-UjozJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292f5a96-541d-4aa4-c2bf-0d2827baa4c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sources/datasetup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lPGabX5alL6K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BATCHSIZE = 32\n",
        "# NUMWORKERS = 1\n",
        "\n",
        "# from torchvision import transforms\n",
        "\n",
        "# train_transform = transforms.Compose([\n",
        "#     transforms.Resize(size=(64, 64)),\n",
        "#     transforms.ToTensor()\n",
        "# ])\n",
        "\n",
        "# test_transform = transforms.Compose([\n",
        "#     transforms.Resize(size=(64, 64)),\n",
        "#     transforms.ToTensor()\n",
        "# ])\n",
        "\n",
        "# train_dataloader, test_dataloader, class_names = create_dataloaders(\n",
        "#     train_dir= train_dir,\n",
        "#     test_dir = test_dir,\n",
        "#     train_transform = train_transform,\n",
        "#     test_transform = test_transform,\n",
        "#     batch_size = BATCHSIZE,\n",
        "#     num_workers=NUMWORKERS\n",
        "# )\n",
        "\n",
        "# len(train_dataloader), len(test_dataloader)\n",
        "# img_batch, label_batch = next(iter(train_dataloader))\n",
        "# img_batch.shape, label_batch.shape\n"
      ],
      "metadata": {
        "id": "FV5FJmgsmRxo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sources/engine.py\n",
        "\n",
        "# main engine\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class tinyVGG(nn.Module):\n",
        "    def __init__(self, name: str, inp_shape: int, out_shape: int, hidden_units=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.name = name\n",
        "\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=inp_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=hidden_units*16*16, out_features=out_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.classifier(self.block_2(self.block_1(x)))\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer):\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    # initialize train loss and accuracy\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # loop over dataloader batch\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "        # compute train logit\n",
        "        train_logit = model(X)\n",
        "\n",
        "        # compute loss\n",
        "        loss = loss_fn(train_logit, y)\n",
        "\n",
        "        # accumulate train loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # zero optimizer gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # back propagation\n",
        "        loss.backward()\n",
        "\n",
        "        # optimizer steps\n",
        "        optimizer.step()\n",
        "\n",
        "        # predict image labels\n",
        "        y_pred = torch.argmax(torch.softmax(train_logit, dim=1), dim=1)\n",
        "\n",
        "        # compute and accumulate accuracy based on predicted labels\n",
        "        train_acc += (y_pred == y).sum().item() / len(y_pred)\n",
        "\n",
        "    # adjust train loss and accuracy\n",
        "    train_loss /= len(dataloader)\n",
        "    train_acc /= len(dataloader)\n",
        "\n",
        "    # return train loss and accuracy\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module):\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # initialize test loss and accuracy\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    # loop over dataloader batch\n",
        "    with torch.inference_mode():\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "            # compute test logit\n",
        "            test_logit = model(X)\n",
        "\n",
        "            # compute and accumulate test loss\n",
        "            test_loss += loss_fn(test_logit, y).item()\n",
        "\n",
        "            # compute test labels\n",
        "            y_pred = torch.argmax(torch.softmax(test_logit, dim=1), dim=1)\n",
        "\n",
        "            # compute and accumulate test accuracy\n",
        "            test_acc += (y_pred == y).sum().item() / len(y_pred)\n",
        "\n",
        "        # adjust test loss and accuracy\n",
        "        test_loss /= len(dataloader)\n",
        "        test_acc /= len(dataloader)\n",
        "\n",
        "    # return test loss and accuracy\n",
        "    return test_loss, test_acc\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          epochs: int=3):\n",
        "\n",
        "\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        train_loss, train_acc = train_step(\n",
        "            model = model,\n",
        "            dataloader = train_dataloader,\n",
        "            loss_fn = loss_fn,\n",
        "            optimizer = optimizer\n",
        "        )\n",
        "\n",
        "        test_loss, test_acc = test_step(\n",
        "            model = model,\n",
        "            dataloader = test_dataloader,\n",
        "            loss_fn = loss_fn\n",
        "        )\n",
        "\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "\n",
        "        print(f\"epoch: {epoch} | train loss: {train_loss:.3f} | train acc: {train_acc:.3f} | test loss: {test_loss:.3f} | test acc: {test_acc:.3f}\")\n",
        "\n",
        "    return results\n",
        "\n"
      ],
      "metadata": {
        "id": "vKmD0z7imRr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5534d29f-632d-4249-c6fa-57b80e903728"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sources/engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9hy1PVHxL8-u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sources import utils, datasetup, engine\n",
        "\n",
        "# show directory tree\n",
        "utils.list_file_tree()\n",
        "\n",
        "# download data\n",
        "url = \"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\"\n",
        "image_dir, train_dir, test_dir = utils.download_data(url=url)\n",
        "\n",
        "# create train and test dataloader\n",
        "BATCHSIZE = 32\n",
        "NUMWORKERS = 1\n",
        "\n",
        "train_transform, test_transform = datasetup.create_compose_transforms()\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = datasetup.create_dataloaders(\n",
        "    train_dir = train_dir,\n",
        "    test_dir = test_dir,\n",
        "    train_transform = train_transform,\n",
        "    test_transform = test_transform,\n",
        "    batch_size = BATCHSIZE,\n",
        "    num_workers = NUMWORKERS\n",
        ")\n",
        "\n",
        "# create tinyVGG model\n",
        "model_0 = engine.tinyVGG(\n",
        "    name = \"model_0\",\n",
        "    inp_shape = 3,\n",
        "    out_shape = len(class_names),\n",
        "    hidden_units = 10\n",
        ")\n",
        "\n",
        "# setup loss function and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
        "\n",
        "# train model\n",
        "model_0_results = engine.train(\n",
        "    model=model_0,\n",
        "    train_dataloader=train_dataloader,\n",
        "    test_dataloader = test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    optimizer = optimizer,\n",
        "    epochs=1\n",
        ")\n",
        "\n",
        "# save model\n",
        "model_dir = Path(\"SAVED_MODEL\")\n",
        "model_dir.mkdir(parents=True, exist_ok=True)\n",
        "model_saved_path = utils.save_model(\n",
        "    model = model_0,\n",
        "    model_dir = model_dir\n",
        ")\n"
      ],
      "metadata": {
        "id": "PYk4lURPmRmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19415a92-69a5-4572-f5f1-f53c84dc899c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \u001b[94m . \u001b[0m\n",
            "    \u001b[94m ./.config \u001b[0m\n",
            "       \u001b[94m ./.config/configurations \u001b[0m\n",
            "       \u001b[94m ./.config/logs \u001b[0m\n",
            "          \u001b[94m ./.config/logs/2023.10.18 \u001b[0m\n",
            "    \u001b[94m ./sources \u001b[0m\n",
            "       \u001b[94m ./sources/__pycache__ \u001b[0m\n",
            "    \u001b[94m ./data \u001b[0m\n",
            "       \u001b[94m ./data/images \u001b[0m\n",
            "          \u001b[94m ./data/images/test \u001b[0m\n",
            "             \u001b[94m ./data/images/test/pizza \u001b[0m\n",
            "             \u001b[94m ./data/images/test/steak \u001b[0m\n",
            "             \u001b[94m ./data/images/test/sushi \u001b[0m\n",
            "          \u001b[94m ./data/images/train \u001b[0m\n",
            "             \u001b[94m ./data/images/train/pizza \u001b[0m\n",
            "             \u001b[94m ./data/images/train/steak \u001b[0m\n",
            "             \u001b[94m ./data/images/train/sushi \u001b[0m\n",
            "    \u001b[94m ./sample_data \u001b[0m\n",
            "epoch: 0 | train loss: 1.114 | train acc: 0.305 | test loss: 1.112 | test acc: 0.260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_0 = engine.tinyVGG(\n",
        "    name = \"loaded_model_0\",\n",
        "    inp_shape = 3,\n",
        "    out_shape = len(class_names),\n",
        "    hidden_units = 10\n",
        ")\n",
        "\n",
        "loaded_model_0.load_state_dict(torch.load(f = model_saved_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73YS9Rkqdhpl",
        "outputId": "7130f16a-3ed1-4f0b-a147-1c6e88be6b3b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "loaded_model_1 = engine.tinyVGG(\n",
        "    name = \"loaded_model_1\",\n",
        "    inp_shape=3,\n",
        "    out_shape=len(class_names),\n",
        "    hidden_units = 10\n",
        ")\n",
        "\n",
        "load_saved_model(\n",
        "    loaded_model = loaded_model_1,\n",
        "    model_saved_path = model_saved_path\n",
        ")"
      ],
      "metadata": {
        "id": "YnZw09W4gY1n"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jBA6KEfdhVS7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CNt_uir9iafR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vgntsRawy3Ar"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MZRLx3GL2D1O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WChis1IRinTa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ovsXP--v2Fo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UbCMfoWAxnZ3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oyRGZzUD0Ejb"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}